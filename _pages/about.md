---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

*I'm looking for research/applied scientist internship for summer/fall 2024. Don't hesitate to contact me if there is a match!*
<br/>

Research Focus
======
I am broadly interested in **reasoning**, which (IMHO) is a key aspect of human intelligence that sets us apart from other species. In the realm of reasoning, I've worked on:
- **Building general-purpose verifier** through rationale extraction from unlabelled data to provide process supervision during reasoning
- **Logical reasoning** that uses theorem prover [Lean](https://lean-lang.org/) to help with the reasoning process [[2]](https://arxiv.org/abs/2403.13312)
- **Decompositional entailment** that formulates a consistent and theoretically grounded approach to annotating decompositional entailment dataset [[3]](https://arxiv.org/abs/2402.14798)

I'm also interested in the **self-improvement** capability of LLMs. If we begin with the “end” (superintelligence/AGI) in mind, relying on human input won't get us there. We need to teach models to interact with the environment and self-improve. Specifically, I've worked on:
- **Understanding the reason** that prevents LLM from effective self-improvement [[1]](https://arxiv.org/abs/2404.04298)
- **Building an environment** that provides faithful feedback for self-improvement
- **Incorporating reasoning techniques** to solve issues during self-improvement

<br/>
The role of training data and alignment in reasoning and self-improvement has always fascinated me. I would like to explore this further when I have more time and resources.
<br/>

Selected Publications
======
* [**SELF-[IN]CORRECT: LLMs Struggle with Refining Self-Generated Responses**](https://arxiv.org/abs/2404.04298)  
**Dongwei Jiang**, Jingyu Zhang, Orion Weller, Nathaniel Weir, Benjamin Van Durme, Daniel Khashabi.
arxiv preprint, 2024.

* [**LeanReasoner: Boosting Complex Logical Reasoning with Lean**](https://arxiv.org/pdf/2403.13312.pdf)  
**Dongwei Jiang**, Marcio Fonseca, Shay B. Cohen.
NAACL Main Conference, 2024.

* [**Enhancing Systematic Decompositional Natural Language Inference Using Informal Logic**](https://arxiv.org/abs/2402.14798)  
Nathaniel Weir, Kate Sanders, Orion Weller, Shreya Sharma, **Dongwei Jiang**, Zhengping Jiang, Bhavana Dalvi Mishra, Oyvind Tafjord, Peter Jansen, Peter Clark, Benjamin Van Durme.
arxiv preprint, 2024.

(for a full publication, please visit my [Google Scholar](https://scholar.google.com/citations?user=z1PXZDEAAAAJ&hl=en))

<br/>

More About Me
======
With six years of industry and research experience in speech processing and self-supervised models, my focus is shifting to LLM. To that end, I'm currently studying at JHU as a master's student, working with Professor [Daniel Khashabi](https://danielkhashabi.com/) and [Benjamin Van Drume](https://www.cs.jhu.edu/~vandurme/). I've also worked with Professor [Shay Cohen](https://homepages.inf.ed.ac.uk/scohen/) from Edinburgh and [Greg Durrett](https://www.cs.utexas.edu/~gdurrett/) from UTA.

Reflecting on my career, I've observed a pattern where significant external events have impacted my role. 
While I was getting comfortable with my role at DiDi, the company encountered [serious regulatory issues](https://www.forbes.com/sites/ywang/2022/05/24/didi-to-delist-from-nyse-after-overwhelming-yes-vote-by-shareholders/?sh=4d105596cba0) with the Chinese government, resulting in its delisting from New York Stock Exchange.
During my time at YuanFuDao, the [Double Reduction Policy](https://en.wikipedia.org/wiki/Double_Reduction_Policy) was introduced, which imposed strict restrictions on YuanFuDao's core business operations.
As I was adapting to my position at Shopee, the company's stock price dropped 80% due to the global economic crisis and the tensions between China and the US, leading to its [extensive layoffs](https://techwireasia.com/2022/09/why-is-e-commerce-giant-shopee-on-a-layoff-spree/).

In my free time, I sometimes play Civ 6 or Hearthstone. I also run and go bouldering every other day - well, more like every three or four days, but who's counting?
